struct ExploitabilityMDP{G, P, S, A} <: MDP{S,A}
    game::G
    policy::P
    exploiter::Int
    function ExploitabilityMDP(game::G, policy, exploiter::Int) where G <: MG
        S = statetype(game)
        A = actiontype(game).types[exploiter] # assuming action type is tuple
        return new{G, typeof(policy), S, A}(game, policy, exploiter)
    end
end

POMDPs.states(mdp::ExploitabilityMDP) = states(mdp.game)
POMDPs.stateindex(mdp::ExploitabilityMDP, s) = stateindex(mdp.game, s)
POMDPs.actions(mdp::ExploitabilityMDP) = actions(mdp.game)[mdp.exploiter]
POMDPs.actionindex(mdp::ExploitabilityMDP, a) = player_actionindex(mdp.game, mdp.exploiter, a)
POMDPs.discount(mdp::ExploitabilityMDP) = discount(mdp.game)
POMDPs.initialstate(mdp::ExploitabilityMDP) = initialstate(mdp.game)

player_reward(p::Int, r::Tuple) = r[p]

player_reward(p::Int, r::Number) = isone(p) ? r : -r

function POMDPs.gen(mdp::ExploitabilityMDP, s, a, rng=Random.default_rng())
    (; game, policy, exploiter) = mdp
    a_pol = rand(rng, behavior(policy, s)[other_player(exploiter)])
    a_joint = isone(exploiter) ? (a, a_pol) : (a_pol, a)
    sp, r = @gen(:sp, :r)(game, s, a_joint, rng)
    r = player_reward(exploiter, r)
    return (; sp, r)
end

function POMDPs.transition(mdp::ExploitabilityMDP, s, a_i)
    (; game, policy, exploiter) = mdp
    exploitee = MarkovGames.other_player(exploiter)
    σ_ni = behavior(policy, s)[exploitee]
    vals = statetype(mdp)[]
    probs = Float64[]
    for a_ni ∈ actions(game)[exploitee]
        a = isone(exploiter) ? (a_i, a_ni) : (a_ni, a_i)
        p_a_ni = pdf(σ_ni, a_ni)
        Tsa = transition(game, s, a)
        for (sp, p) in weighted_iterator(Tsa)
            idx = findfirst(==(sp), vals)
            if isnothing(idx)
                push!(vals, sp)
                push!(probs, p_a_ni * p)
            else
                probs[idx] += p_a_ni * p
            end
        end
    end
    return SparseCat(vals, probs)
end

